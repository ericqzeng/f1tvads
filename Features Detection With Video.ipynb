{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from sortedcontainers import SortedKeyList, SortedDict\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOB subtractor\n",
    "subtractor = cv2.createBackgroundSubtractorMOG2(detectShadows=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kp and des methods\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "def siftKpAndDes(frame):\n",
    "    return sift.detectAndCompute(frame,None)\n",
    "\n",
    "surf = cv2.xfeatures2d.SURF_create()\n",
    "def surfKpAndDes(frame):\n",
    "    return surf.detectAndCompute(frame,None)\n",
    "\n",
    "star = cv2.xfeatures2d.StarDetector_create()\n",
    "def fastKp(frame):\n",
    "    return star.detect(frame,None)\n",
    "\n",
    "brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "def briefDes(frame, kps):\n",
    "    return brief.compute(frame, kps)\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "def orbKpAndDes(frame):\n",
    "    return orb.detectAndCompute(frame,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matcher methods\n",
    "\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "FLANN_KDTREES = 5\n",
    "\n",
    "FLANN_INDEX_LSH = 6\n",
    "TABLE_NUMBER = 6 #12\n",
    "KEY_SIZE = 12 #20\n",
    "MULTI_PROBE_LEVEL = 1 #2\n",
    "SEARCH_CHECKS = 50\n",
    "\n",
    "#BF matching\n",
    "bf_orb = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "bf_sift = cv2.BFMatcher()\n",
    "def bfMatcher(des1, des2, feature_type = 'SIFT', ratio = 0.7):\n",
    "\n",
    "    if feature_type is 'ORB': \n",
    "        matches = bf_orb.knnMatch(des1,des2,k=2)\n",
    "    else:\n",
    "        matches = bf_sift.knnMatch(des1, des2, k=2)\n",
    "    # filter using ratio\n",
    "    good = []\n",
    "    for pair in matches:\n",
    "        try:\n",
    "            m,n = pair\n",
    "            if m.distance < ratio*n.distance:\n",
    "                good.append(m)\n",
    "        except ValueError:\n",
    "            print('Missing Match pair!')\n",
    "            pass\n",
    "    return good, matches\n",
    "\n",
    "\n",
    "#FLANN-based\n",
    "search_params = dict(checks = SEARCH_CHECKS)\n",
    "flann_orb = cv2.FlannBasedMatcher(dict(algorithm = FLANN_INDEX_LSH,\n",
    "                   table_number = TABLE_NUMBER,\n",
    "                   key_size = KEY_SIZE,\n",
    "                   multi_probe_level = MULTI_PROBE_LEVEL),\n",
    "                   search_params)\n",
    "flann_sift = cv2.FlannBasedMatcher(dict(algorithm = FLANN_INDEX_KDTREE, trees = FLANN_KDTREES), \n",
    "                                   search_params )\n",
    "def flannMatcher(des1, des2, feature_type = 'SIFT', ratio=0.7):\n",
    "    \n",
    "    if feature_type is 'ORB': \n",
    "        matches = flann_orb.knnMatch(des1, des2, k=2)\n",
    "    else:\n",
    "        matches = flann_sift.knnMatch(des1, des2, k=2)\n",
    "    # filter using ratio\n",
    "    good = []\n",
    "    for pair in matches:\n",
    "        try:\n",
    "            m,n = pair\n",
    "            if m.distance < ratio*n.distance:\n",
    "                good.append(m)\n",
    "        except ValueError:\n",
    "            print('Missing Match pair!')\n",
    "            pass\n",
    "    return good, matches\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersection of two segments given their endpoints\n",
    "# This code is contributed by Ansh Riyal \n",
    "\n",
    "# Hash, String, and comparison definitions provided by Eric Zeng\n",
    "class Point: \n",
    "    def __init__(self, x, y): \n",
    "        self.x = x \n",
    "        self.y = y\n",
    "        self.key = x * 1000 + y * 1000\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return (self.x == other.x) and (self.y == other.y)\n",
    "        \n",
    "    def __lt__(self, other):\n",
    "        return self.x < other.x or (self.x == other.x and self.y < other.y)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Point(\" + str(self.x).zfill(5) + \", \" + str(self.y).zfill(5) + \")\"\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(str(self.x) + ',' + str(self.y))\n",
    "        \n",
    "  \n",
    "# Given three colinear points p, q, r, the function checks if  \n",
    "# point q lies on line segment 'pr'  \n",
    "def onSegment(p, q, r): \n",
    "    if ( (q.x <= max(p.x, r.x)) and (q.x >= min(p.x, r.x)) and \n",
    "           (q.y <= max(p.y, r.y)) and (q.y >= min(p.y, r.y))): \n",
    "        return True\n",
    "    return False\n",
    "  \n",
    "def orientation(p, q, r): \n",
    "    # to find the orientation of an ordered triplet (p,q,r) \n",
    "    # function returns the following values: \n",
    "    # 0 : Colinear points \n",
    "    # 1 : Clockwise points \n",
    "    # 2 : Counterclockwise \n",
    "      \n",
    "    # See https://www.geeksforgeeks.org/orientation-3-ordered-points/amp/  \n",
    "    # for details of below formula.  \n",
    "      \n",
    "    val = (float(q.y - p.y) * (r.x - q.x)) - (float(q.x - p.x) * (r.y - q.y)) \n",
    "    if (val > 0): \n",
    "          \n",
    "        # Clockwise orientation \n",
    "        return 1\n",
    "    elif (val < 0): \n",
    "          \n",
    "        # Counterclockwise orientation \n",
    "        return 2\n",
    "    else: \n",
    "          \n",
    "        # Colinear orientation \n",
    "        return 0\n",
    "  \n",
    "# the main function that returns true if  \n",
    "# the line segment 'p1q1' and 'p2q2' intersect. \n",
    "def doIntersect(p1,q1,p2,q2): \n",
    "      \n",
    "    # Find the 4 orientations required for  \n",
    "    # the general and special cases \n",
    "    o1 = orientation(p1, q1, p2) \n",
    "    o2 = orientation(p1, q1, q2) \n",
    "    o3 = orientation(p2, q2, p1) \n",
    "    o4 = orientation(p2, q2, q1) \n",
    "  \n",
    "    # General case \n",
    "    if ((o1 != o2) and (o3 != o4)): \n",
    "        return True\n",
    "  \n",
    "    # Special Cases \n",
    "  \n",
    "    # p1 , q1 and p2 are colinear and p2 lies on segment p1q1 \n",
    "    if ((o1 == 0) and onSegment(p1, p2, q1)): \n",
    "        return True\n",
    "  \n",
    "    # p1 , q1 and q2 are colinear and q2 lies on segment p1q1 \n",
    "    if ((o2 == 0) and onSegment(p1, q2, q1)): \n",
    "        return True\n",
    "  \n",
    "    # p2 , q2 and p1 are colinear and p1 lies on segment p2q2 \n",
    "    if ((o3 == 0) and onSegment(p2, p1, q2)): \n",
    "        return True\n",
    "  \n",
    "    # p2 , q2 and q1 are colinear and q1 lies on segment p2q2 \n",
    "    if ((o4 == 0) and onSegment(p2, q1, q2)): \n",
    "        return True\n",
    "  \n",
    "    # If none of the cases \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line class by Eric Zeng\n",
    "class Line:\n",
    "    def __init__(self, p, q):\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "        self.key = str(p.y).zfill(5) + str(q.y).zfill(5) # lines should be sorted by the y-coors\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return (self.p is other.p and self.q is other.q)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.p < other.p\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Line[\" + str(self.p).zfill(5) + \"-\" + str(self.q).zfill(5) + \"]\"\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(str(self.p) + '-' + str(self.q))\n",
    "    \n",
    "# Evaluates if two lines share any endpoints    \n",
    "def endsCoincident(p1, p2):\n",
    "#     print(\"COINCIDENT EP TEST\")\n",
    "#     print(p1.p)\n",
    "#     print(p1.q)\n",
    "#     print(p2.p)\n",
    "#     print(p2.q)\n",
    "#     print(p1.p == p2.p)\n",
    "#     print(p1.p == p2.q)\n",
    "#     print(p1.q == p2.p)\n",
    "#     print(p1.q == p2.q)\n",
    "    return (p1.p == p2.p) or (p1.p == p2.q) or (p1.q == p2.p) or (p1.q == p2.q)\n",
    "\n",
    "# assumes pts are 4 points creating a closed quad\n",
    "# electing to use list instead of BST or other varients since n=4 (finite, known, and very small)\n",
    "# This implementation was written by Eric Zeng\n",
    "def checkSimplePolygon(pts):\n",
    "    print('INTERSECTION CHECK')\n",
    "#     print(pts)\n",
    "\n",
    "    # create 4 segments\n",
    "    # sort the endpoints in each segment to have the smaller x value be first\n",
    "    segs = [\n",
    "            sorted([Point(int(pts[0][0][0] + 10000), int(pts[0][0][1] + 10000)), \n",
    "                    Point(int(pts[1][0][0] + 10000), int(pts[1][0][1] + 10000))]), \n",
    "            sorted([Point(int(pts[1][0][0] + 10000), int(pts[1][0][1] + 10000)), \n",
    "                    Point(int(pts[2][0][0] + 10000), int(pts[2][0][1] + 10000))]),\n",
    "            sorted([Point(int(pts[2][0][0] + 10000), int(pts[2][0][1] + 10000)), \n",
    "                    Point(int(pts[3][0][0] + 10000), int(pts[3][0][1] + 10000))]),\n",
    "            sorted([Point(int(pts[3][0][0] + 10000), int(pts[3][0][1] + 10000)), \n",
    "                    Point(int(pts[0][0][0] + 10000), int(pts[0][0][1] + 10000))])\n",
    "           ]\n",
    "    # sort all segments against each other using the starting endpoint's x value\n",
    "    segs = sorted(segs, key = lambda x: x[0])\n",
    "#     [print(str(s[0]) + ', ' + str(s[1])) for s in segs]\n",
    "    segs = [Line(s[0], s[1]) for s in segs] # covert sublists to lines\n",
    "    \n",
    "    # init event queue, marking {\"Adds\" and \"Exit\" endpoints -> Line} mappings\n",
    "    eventq = SortedDict()\n",
    "    for s in segs:\n",
    "        left = str(s.p) + 'A'\n",
    "        right = str(s.q) + 'E'\n",
    "        if (left not in eventq):\n",
    "            eventq.update({left: list()})\n",
    "        if (right not in eventq):\n",
    "            eventq.update({right: list()})\n",
    "            \n",
    "        eventq.get(left).append(s)\n",
    "        eventq.get(right).append(s)\n",
    "    \n",
    "#     print(\"EVENT QUEUE ORDER: \")\n",
    "#     [print(a) for a in eventq]\n",
    "\n",
    "    # init sweep line\n",
    "    sl = SortedKeyList([], key=lambda x: x.key)\n",
    "    for e in eventq:\n",
    "#         print(e)\n",
    "#         print('targets: ' + \",\".join(str(line) for line in eventq[e]))\n",
    "#         print('SL: ' + \",\".join(str(line) for line in sl))\n",
    "        if e[-1] is 'A':\n",
    "#             print('ADDS')\n",
    "            for line in eventq[e]:\n",
    "                sl.add(line)\n",
    "#                 print(line)\n",
    "                try: \n",
    "#                     print('above')\n",
    "                    above = sl[sl.index(line) + 1]\n",
    "                    if (not endsCoincident(above, line)) and doIntersect(above.p, above.q, line.p, line.q):\n",
    "#                         print('above FALSE')\n",
    "                        return False\n",
    "                except IndexError:\n",
    "#                     print('above index error')\n",
    "                    pass # missing above\n",
    "                try: \n",
    "#                     print('below')\n",
    "                    below = sl[sl.index(line) - 1]\n",
    "                    if (not endsCoincident(below, line)) and doIntersect(below.p, below.q, line.p, line.q):\n",
    "#                         print('below FALSE')\n",
    "                        return False\n",
    "                except IndexError:\n",
    "#                     print('below index error')\n",
    "                    pass # missing above\n",
    "        else: # e[0] is 'E'\n",
    "#             print('REMOVES')\n",
    "            for line in eventq[e]:\n",
    "                # check above and below intersections if not conincident\n",
    "#                 print(line)\n",
    "                try:\n",
    "#                     print('both')\n",
    "                    above = sl[sl.index(line) + 1]\n",
    "                    below = sl[sl.index(line) - 1]\n",
    "                    if (not endsCoincident(above, below)) and doIntersect(above.p, above.q, below.p, below.q):\n",
    "#                         print('both FALSE')\n",
    "                        return False\n",
    "                except IndexError:\n",
    "#                     print('both index error')\n",
    "                    pass # missing either/both line above or below in SL, no need for additional check\n",
    "                 \n",
    "                # once check is done, discard this line from the SL\n",
    "                \n",
    "                sl.remove(line)\n",
    "\n",
    "#         [print(l) for l in sl]\n",
    "#         print()\n",
    "    return True\n",
    "\n",
    "# testpoly = [[[30, 30]], [[56, 56]], [[52, 32]], [[32, 52]] ]\n",
    "\n",
    "# test = cv2.polylines(img1,[np.int32(testpoly)],True,(0,255,0),3, cv2.LINE_AA)  \n",
    "# plt.figure(figsize=(20,20))\n",
    "# plt.imshow(test)\n",
    "\n",
    "# checkSimplePolygon(testpoly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 program to evaluate \n",
    "# area of a polygon using \n",
    "# shoelace formula, clockwise in opencv coordinate system\n",
    "# \n",
    "# NOTE: assumes polygon is simple and closed (non-intersecting)\n",
    "# please check before simple property before running\n",
    "# (X[i], Y[i]) are coordinates of i'th point. \n",
    "# This code is contributed by Smitha Dinesh Semwal \n",
    "# https://www.geeksforgeeks.org/area-of-a-polygon-with-given-n-ordered-vertices/\n",
    "def shoelace(points): \n",
    "    \n",
    "    #transform list of Point object to two lists of X and Y coordinates\n",
    "    X = []\n",
    "    Y = []\n",
    "    for p in points:\n",
    "        X.append(p.x)\n",
    "        Y.append(p.y)\n",
    "  \n",
    "    # Initialze area \n",
    "    area = 0.0\n",
    "  \n",
    "    # Calculate value of shoelace formula \n",
    "    j = len(points) - 1\n",
    "    for i in range(0,len(points)): \n",
    "        area += (X[j] + X[i]) * (Y[j] - Y[i]) \n",
    "        j = i   # j is previous vertex to i \n",
    "      \n",
    "  \n",
    "    # Return absolute value \n",
    "    return abs(area / 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Polygon Area comparison utilizing shoelace above\n",
    "def checkArea(pts, total_area, min_area):\n",
    "    print('AREA CHECK')\n",
    "    points = [\n",
    "        Point(pts[0][0][0], pts[0][0][1]),\n",
    "        Point(pts[1][0][0], pts[1][0][1]),\n",
    "        Point(pts[2][0][0], pts[2][0][1]),\n",
    "        Point(pts[3][0][0], pts[3][0][1]),\n",
    "    ]\n",
    "    area = shoelace(points)\n",
    "    ratio = area / total_area\n",
    "    return (ratio < 1.0 and ratio > min_area), ratio\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interior angle measures function\n",
    "# assumes quadilateral is non-intersecting! Check before running or function outpus garbage\n",
    "#\n",
    "# Algorithm from:\n",
    "# https://math.stackexchange.com/questions/149959/how-to-find-the-interior-angle-of-an-irregular-pentagon-or-polygon\n",
    "#\n",
    "# Implementation by Eric Zeng\n",
    "def measureAngles(pts, min_angle, max_angle):\n",
    "    print('ANGLE CHECK')\n",
    "    points = [\n",
    "        Point(pts[0][0][0], pts[0][0][1]),\n",
    "        Point(pts[1][0][0], pts[1][0][1]),\n",
    "        Point(pts[2][0][0], pts[2][0][1]),\n",
    "        Point(pts[3][0][0], pts[3][0][1]),\n",
    "    ]\n",
    "    \n",
    "    angles = []\n",
    "    \n",
    "    #start top left, go CW in opencv coordinate space\n",
    "    for i in range(4):\n",
    "        past = points[i-1]\n",
    "        curr = points[i]\n",
    "        nxt = points[i+1] if i < 3 else points[0]\n",
    "        vec1 = Point(curr.x - past.x, curr.y - past.y)\n",
    "        vec2 = Point(nxt.x - curr.x, nxt.y - curr.y)\n",
    "        vec1m = [vec1.x, vec1.y, 0]\n",
    "        vec2m = [vec2.x, vec2.y, 0]\n",
    "        cp = np.cross(vec1m, vec2m) # cross product for direction check \n",
    "\n",
    "        value = np.dot(vec1m, vec2m)/(math.sqrt(vec1.x**2 + vec1.y**2)*math.sqrt(vec2.x**2 + vec2.y**2))\n",
    "        value = -1 * value if cp[2] < 0 else value\n",
    "        angles.append(math.pi - math.acos(value))\n",
    "    \n",
    "    angles = [x*180/math.pi for x in angles] # to degrees\n",
    "    if (sum(angles) > 180): # slightly above 2*pi for floating point inaccuracies\n",
    "        angles = [x - math.pi for x in angles]\n",
    "    return (not any([x > max_angle or x < min_angle for x in angles])), angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point in Polygon (Contour) filter\n",
    "# Used to deterine which keypoints are within the bounding box of a homography transformation; True if inside\n",
    "# Implementation by Eric Zeng\n",
    "def filterPoints(pts, h_pts):\n",
    "    contour = np.array([[p[0][0], p[0][1]] for p in h_pts])\n",
    "    ret = []\n",
    "    for point in pts:\n",
    "        ret.append(False if cv2.pointPolygonTest(contour, (point[0], point[1]), False) < 0 else True)\n",
    "    return ret\n",
    "\n",
    "# cv2.drawContours(img1, [pts], 0, (255,255,255), 1)\n",
    "# print(cv2.pointPolygonTest(pts, (10,10), False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Container class to represent a positive match to be saved in our CSV output\n",
    "# Author: Eric Zeng\n",
    "class PositiveMatch:\n",
    "    def __init__(self, img, name, area, smallest_angle, largest_angle, cwf):\n",
    "        self.img = img\n",
    "        self.name = name\n",
    "        self.area = area\n",
    "        self.smallest_angle = smallest_angle\n",
    "        self.largest_angle = largest_angle\n",
    "        self.cwf = cwf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to output results to CSV\n",
    "# Author: Eric Zeng\n",
    "def outputCSV(positives, errors, query, video, output_dir, chain, feature_ext, matcher,\n",
    "               frame_interval, ratio, min_matches, fps,\n",
    "                min_area, allow_intersections, min_angle, max_angle):\n",
    "    print(\"Analysis finished!\")\n",
    "    # TODO: post-processing of CSV and image files\n",
    "    # TOTO: consider saving dict of positives alongside csv file to allow for futher analytics\n",
    "    # TODO: write out detailed Errors too\n",
    "    with open(os.path.join(output_dir,'results.csv'), 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['SUMMARY OF PARAMS'])\n",
    "        writer.writerow(['Query Image', 'Video', 'Chain Length', 'Feature Extractor', 'Matcher', \n",
    "                         'Frame Interval', 'Pass Ratio', 'Match Thresh',\n",
    "                        'Min Area', 'Filter Intersections', 'Min Angle', 'Max Angle'])\n",
    "        writer.writerow([query, video, chain, feature_ext, matcher, frame_interval, ratio, min_matches,\n",
    "                        min_area, not allow_intersections, min_angle, max_angle])\n",
    "        writer.writerow(['MATCHES'])\n",
    "        writer.writerow(['Frame Num', 'Img Name', 'Area','Min Angle', 'Max Angle', 'Chain Weight Factor'])\n",
    "        for match in positives.items():\n",
    "            writer.writerow([match[0], match[1].name, match[1].area, match[1].smallest_angle, match[1].largest_angle,\n",
    "                             match[1].cwf])\n",
    "            # TODO: more metadata later; consider making a PositiveMatch class as a container object\n",
    "        writer.writerow(['ERRORS'])\n",
    "        for err in errors:\n",
    "            writer.writerow([err])\n",
    "            \n",
    "# Adds on-screen display information to the target img\n",
    "def addOSD(tgt, n_pos, chain_n, frame_n, delta):\n",
    "    cv2.putText(tgt, \"T.Count: \" + str(n_pos), (2,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    cv2.putText(tgt, \"Pos.Chain: \" + str(chain_n), (2,60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    cv2.putText(tgt, \"Frame.Num: \" + str(frame_n) + delta, (2, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess kp/des for query image(s)\n",
    "\n",
    "img1 = cv2.imread('logos/genii.jpg',0) # queryImage\n",
    "# find the keypoints and descriptors\n",
    "kp1, des1 = siftKpAndDes(img1)\n",
    "\n",
    "img1kps = cv2.drawKeypoints(img1, kp1, None, color=(0,255,0), flags=0)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(img1kps), plt.show()\n",
    "\n",
    "print(len(kp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding params for quality when saving sample jpeg screenshots\n",
    "encoding_params = [int(cv2.IMWRITE_JPEG_QUALITY), 10]\n",
    "\n",
    "def runMatching(query, video, output_dir=\"outputs\", chain = 3, feature_ext = 'ORB', matcher = 'FLANN',\n",
    "               frame_interval = 1, ratio = 0.7, min_matches = 15, fps = 30,\n",
    "                min_area='0.1', allow_intersections = False, min_angle = 45, max_angle = 135):\n",
    "    positives = dict() # dict of frame numbers of positive indentifications\n",
    "    n_pos = 0 # total count of positives\n",
    "    errors = [] # list of error frames to analyze later (hopefully should be empty!)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video)\n",
    "    img_chain = [] # list of past images in the current running chain of positive frames, up to the chain parameter\n",
    "    \n",
    "    # preprocess kp/des for query image(s)\n",
    "    img1 = cv2.imread(query, 0)\n",
    "    if feature_ext is 'ORB':     \n",
    "        kp1, des1 = orbKpAndDes(img1)\n",
    "    elif feature_ext is 'SIFT':\n",
    "        kp1, des1 = siftKpAndDes(img1)\n",
    "    else:\n",
    "        # no features or matching\n",
    "        kp1, des1 = [], []\n",
    "    \n",
    "    \n",
    "    # frame number tracker\n",
    "    frame_n = 0\n",
    "    \n",
    "    # start time for running speed measure\n",
    "    start_t = time.process_time()\n",
    "    delta = ''\n",
    "    \n",
    "    while(True):\n",
    "        for i in range(frame_interval - 1):\n",
    "            #skip i number of frames\n",
    "            cap.grab()\n",
    "\n",
    "        # Capture frame-by-frame and covert to grayscale\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break # exit when done\n",
    "            \n",
    "        frame_n += 1 # ret is True, frame found, continue processing\n",
    "        \n",
    "        # running speed display (delta is % speed of realtime according to input fps and frame interval)\n",
    "        if frame_n % fps is 0:\n",
    "            end_t = time.process_time()\n",
    "            delta = int((100.0 * frame_interval) / (end_t - start_t))\n",
    "            delta = \" (\" + str(delta) + \"%)\"\n",
    "            print(delta)\n",
    "            start_t = time.process_time()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#         # TESTING: MOG2 background subtractor mask\n",
    "#         mask = subtractor.apply(gray, masked, 0.999)\n",
    "#         masked = cv2.bitwise_and(gray, masked)\n",
    "#         kp2, des2 = siftKpAndDes(masked)\n",
    "\n",
    "#         # TESTING: Equalize historgram to incrase contrast (probably for ORB)\n",
    "#         eh = cv2.equalizeHist(gray)\n",
    "#         kp2, des2 = siftKpAndDes(eh)\n",
    "\n",
    "#         # TESTING: Blurring with various LPFs\n",
    "#         blurred = cv2.bilateralFilter(gray,9,75,75)\n",
    "#         kp2, des2 = siftKpAndDes(blurred)\n",
    "\n",
    "        # DEFAULT: find the keypoints and descriptors\n",
    "        if feature_ext is 'ORB':     \n",
    "            kp2, des2 = orbKpAndDes(gray)\n",
    "        elif feature_ext is 'SIFT':\n",
    "            kp2, des2 = siftKpAndDes(gray)\n",
    "        else:\n",
    "            # no features or matching\n",
    "            cv2.putText(gray, \"Frame.Num: \" + str(frame_n) + delta, (2, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "            cv2.imshow('frame', gray)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            continue\n",
    "            \n",
    "        # kp/des generation done, we can covert back to color so homography lines can be shown\n",
    "        img3 = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        add_to_chain = False # flag: if we should record this video frame to the img_chain\n",
    "        total_area = 0 # total % coverage by all valid homography matches\n",
    "        allAngles = [] # list of all angles in all valid homography matches\n",
    "        \n",
    "        # loop and keeping finding valid matches w/ homography until no more in this video frame\n",
    "        while True:\n",
    "\n",
    "            # list of good matches (need to init to empty for debug mode)\n",
    "            good = []\n",
    "\n",
    "            # check flags\n",
    "            areaCheck = False\n",
    "            intersectionCheck = False\n",
    "            angleCheck = False\n",
    "            try:\n",
    "                if matcher is 'FLANN':\n",
    "                    good, matches = flannMatcher(des1, des2, feature_type=feature_ext, ratio=ratio)\n",
    "                elif matcher is 'BF':\n",
    "                    good, matches = bfMatcher(des1, des2, feature_type=feature_ext, ratio=ratio)\n",
    "                else:\n",
    "                    # DEBUGGING: show only target image kps, no matching run\n",
    "                    img3 = cv2.drawKeypoints(img3, kp2, None, color=(0,255,0), flags=0)\n",
    "                    cv2.putText(img3, \"Frame.Num: \" + str(frame_n) + delta, (2, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "                    cv2.imshow('frame',img3)\n",
    "                    break # break out of this video frame's inner loop\n",
    "\n",
    "                if len(good) > min_matches:\n",
    "                    print((\"Frame%d: \" % frame_n) + str(len(good)) + \" good matches Found\")\n",
    "                    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "                    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "                    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "\n",
    "                    if M is None:\n",
    "                        # if homography matrix is empty\n",
    "                        print(\"Empty homography matrix\")\n",
    "#                         img3 = gray # display image without any lines\n",
    "                        break\n",
    "                    else:\n",
    "    #                     print(M)\n",
    "                        matchesMask = mask.ravel().tolist()\n",
    "                        h,w = img1.shape\n",
    "                        pts = np.float32([ [0,0],[w-1,0],[w-1,h-1],[0,h-1] ]).reshape(-1,1,2) # cw direction\n",
    "                        dst = cv2.perspectiveTransform(pts,M)\n",
    "\n",
    "                        # TODO: analyze shpae of dst, checking it is reasonable\n",
    "                        flat = [coor for pt in dst for c in pt for coor in c] # mark as bad if coordinates are extreme (abs >= 10,000)\n",
    "                        if not any([coor >= 10000 or coor <= -10000 for coor in flat]):\n",
    "                            total_area = gray.shape[0] * gray.shape[1]\n",
    "                            areaCheck, homography_area = checkArea(dst, total_area, min_area) if min_area > 0 else (True, None) # auto pass if min_area is 0\n",
    "                            if areaCheck: # only bother checking intersections if area is OK\n",
    "                                intersectionCheck = checkSimplePolygon(dst) if not allow_intersections else True\n",
    "                                if intersectionCheck: # only bother checking angles if no intersections\n",
    "                                    angleCheck, angles = measureAngles(dst, min_angle, max_angle) if (min_area > 0 and max_angle < 180) else (True, [None])\n",
    "                                    \n",
    "                        if (not areaCheck):\n",
    "                            img3 = cv2.polylines(img3,[np.int32(dst)],True,(0,255,255),3, cv2.LINE_AA)\n",
    "                            break\n",
    "                        elif (not intersectionCheck):\n",
    "                            img3 = cv2.polylines(img3,[np.int32(dst)],True,(0,0,255),3, cv2.LINE_AA)\n",
    "                            break\n",
    "                        elif (not angleCheck):\n",
    "                            img = cv2.polylines(img3,[np.int32(dst)],True,(255,0,0),3, cv2.LINE_AA)\n",
    "                            break\n",
    "                        else:\n",
    "                            print('PASSED ALL HOMOGRAPHY CHECKS')\n",
    "                            img3 = cv2.polylines(img3,[np.int32(dst)],True,(0,255,0),3, cv2.LINE_AA)\n",
    "                            total_area += homography_area\n",
    "                            allAngles.append(angles)\n",
    "                            add_to_chain = True # add to img_chain if we have >= 1 valid homography match\n",
    "                            \n",
    "                            #remove des2 descriptors that are within the homography transformation found\n",
    "                            contour = np.array([[int(p[0][0]), int(p[0][1])] for p in dst])\n",
    "                            kp_xy = np.float32([kp2[idx].pt for idx in range(0, len(kp2))])\n",
    "                            res = filterPoints(kp_xy, dst)\n",
    "                            kp2 = np.array([k for i,k in enumerate(kp2) if not res[i]])\n",
    "                            des2 = np.array([descriptor for i,descriptor in enumerate(des2) if not res[i]])\n",
    "     \n",
    "                else:\n",
    "                    print((\"Frame%d: \" % frame_n) + \"Not enough good matches - {}/{}\".format(len(good), min_matches) )\n",
    "                    matchesMask = None\n",
    "                    break\n",
    "#                     img3 = gray # display image without any lines\n",
    "\n",
    "    #             draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "    #                                singlePointColor = None,\n",
    "    #                                matchesMask = matchesMask, # draw only inliers\n",
    "    #                                flags = 2)\n",
    "    #             img3 = cv2.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    "\n",
    "    #             # Display the resulting frame\n",
    "    #             cv2.imshow('frame',gray)\n",
    "\n",
    "            except cv2.error as e:\n",
    "                print((\"Frame%d: \" % frame_n) + 'Matching Error! Recording and skipping this frame...')\n",
    "#                 img3 = gray # display image without any lines\n",
    "                print(e)\n",
    "                errors.append(e)\n",
    "                break\n",
    "\n",
    "        #  saving samples positives images\n",
    "#         if len(good) > min_matches and M is not None and areaCheck and intersectionCheck and angleCheck:\n",
    "        if add_to_chain:\n",
    "            img_name = 'frame%d.jpg' % frame_n\n",
    "            pm = PositiveMatch(img3, img_name, total_area, min(allAngles), max(allAngles), 1)\n",
    "            img_chain.append(pm) # add this image to the current continuous chain of positive frames\n",
    "            if len(img_chain) is chain:\n",
    "                for i,img_in_chain in enumerate(img_chain):\n",
    "                    n_pos += 1\n",
    "                    addOSD(img3, n_pos, len(img_chain), frame_n, delta) if i is chain - 1 else None\n",
    "                    cv2.imwrite(os.path.join(output_dir, img_in_chain.name), img_in_chain.img, encoding_params) # write with compression param as specified up top\n",
    "                    positives[frame_n - chain + 1 + i] = img_in_chain\n",
    "                    print('RECORDED: ' + str(img_in_chain.name))\n",
    "            elif len(img_chain) > chain:\n",
    "                n_pos += 1\n",
    "                addOSD(img3, n_pos, len(img_chain), frame_n, delta)\n",
    "                cv2.imwrite(os.path.join(output_dir, img_name), img3, encoding_params) # write with compression param as specified up top\n",
    "                positives[frame_n] = pm\n",
    "                print('RECORDED: ' + str(img_name))\n",
    "                \n",
    "                # TODO: save only the single median image in each group of 5?\n",
    "#             if len(img_chain) % chain is 0:\n",
    "\n",
    "            else:\n",
    "                addOSD(img3, n_pos, len(img_chain), frame_n, delta)\n",
    "        \n",
    "        else:\n",
    "            img_chain = [] # if negative, then clear chain\n",
    "            addOSD(img3, n_pos, len(img_chain), frame_n, delta)\n",
    "        \n",
    "        try:\n",
    "            cv2.imshow('frame',img3)\n",
    "            pass\n",
    "        except:\n",
    "            print('IMG converstion failed, skipping...')\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        elif cv2.waitKey(1) & 0xFF == ord('p'):\n",
    "            while True:\n",
    "                if cv2.waitKey(1) & 0xFF == ord('o'):\n",
    "                     break\n",
    "\n",
    "                            \n",
    "               \n",
    "                    \n",
    "\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    # write outputs\n",
    "    outputCSV(positives, errors, query, video, output_dir, chain, feature_ext, matcher,\n",
    "               frame_interval, ratio, min_matches, fps,\n",
    "                min_area, allow_intersections, min_angle, max_angle)\n",
    "    \n",
    "    return positives, n_pos, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runner\n",
    "# TODO: make all params specified here\n",
    "\n",
    "FRAME_INTERVAL = 2 # 1 means no frame skips\n",
    "MIN_MATCH_COUNT =  10 # RULE: >10% of keypoints in query image? -> work well only fort scale-invarient (SIFT)\n",
    "RATIO = 0.7 # lowered from 0.7 to derease sensitivity\n",
    "MIN_AREA = 0.01 # 0 to disable area checking\n",
    "\n",
    "runMatching('logos/rolex.jpg', 'videos/15brazil-5min.mp4', output_dir='outputs', chain=3,\n",
    "            feature_ext = 'ORB', matcher='FLANN',\n",
    "            frame_interval=FRAME_INTERVAL, ratio=RATIO, min_matches=MIN_MATCH_COUNT, fps=50, \n",
    "            min_area=MIN_AREA,  allow_intersections=False, min_angle=45, max_angle= 135)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = np.array([[ 307, -219], [ 858,  -235], [ 822,    280], [ 370, 284]])\n",
    "\n",
    "# cv2.drawContours(img1, [pts], 0, (255,255,255), 1)\n",
    "print(cv2.pointPolygonTest(pts, (300,2999), False))\n",
    "\n",
    "# plt.figure(figsize=(20,20))\n",
    "# plt.imshow(img1), plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
