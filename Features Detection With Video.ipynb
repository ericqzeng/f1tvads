{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOB subtractor\n",
    "subtractor = cv2.createBackgroundSubtractorMOG2(detectShadows=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kp and des methods\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "def siftKpAndDes(frame):\n",
    "    return sift.detectAndCompute(frame,None)\n",
    "\n",
    "surf = cv2.xfeatures2d.SURF_create()\n",
    "def surfKpAndDes(frame):\n",
    "    return surf.detectAndCompute(frame,None)\n",
    "\n",
    "star = cv2.xfeatures2d.StarDetector_create()\n",
    "def fastKp(frame):\n",
    "    return star.detect(frame,None)\n",
    "\n",
    "brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "def briefDes(frame, kps):\n",
    "    return brief.compute(frame, kps)\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "def orbKpAndDes(frame):\n",
    "    return orb.detectAndCompute(frame,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matcher methods\n",
    "\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "FLANN_KDTREES = 5\n",
    "\n",
    "FLANN_INDEX_LSH = 6\n",
    "TABLE_NUMBER = 6 #12\n",
    "KEY_SIZE = 12 #20\n",
    "MULTI_PROBE_LEVEL = 1 #2\n",
    "SEARCH_CHECKS = 50\n",
    "\n",
    "#BF matching\n",
    "bf_orb = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "bf_sift = cv2.BFMatcher()\n",
    "def bfMatcher(des1, des2, feature_type = 'SIFT', ratio = 0.7):\n",
    "\n",
    "    if feature_type is 'ORB': \n",
    "        matches = bf_orb.knnMatch(des1,des2,k=2)\n",
    "    else:\n",
    "        matches = bf_sift.knnMatch(des1, des2, k=2)\n",
    "    # filter using ratio\n",
    "    good = []\n",
    "    for pair in matches:\n",
    "        try:\n",
    "            m,n = pair\n",
    "            if m.distance < ratio*n.distance:\n",
    "                good.append(m)\n",
    "        except ValueError:\n",
    "            print('Missing Match pair!')\n",
    "            passq\n",
    "    return good, matches\n",
    "\n",
    "\n",
    "#FLANN-based\n",
    "search_params = dict(checks = SEARCH_CHECKS)\n",
    "flann_orb = cv2.FlannBasedMatcher(dict(algorithm = FLANN_INDEX_LSH,\n",
    "                   table_number = TABLE_NUMBER,\n",
    "                   key_size = KEY_SIZE,\n",
    "                   multi_probe_level = MULTI_PROBE_LEVEL),\n",
    "                   search_params)\n",
    "flann_sift = cv2.FlannBasedMatcher(dict(algorithm = FLANN_INDEX_KDTREE, trees = FLANN_KDTREES), \n",
    "                                   search_params )\n",
    "def flannMatcher(des1, des2, feature_type = 'SIFT', ratio=0.7):\n",
    "    \n",
    "    if feature_type is 'ORB': \n",
    "        matches = flann_orb.knnMatch(des1, des2, k=2)\n",
    "    else:\n",
    "        matches = flann_sift.knnMatch(des1, des2, k=2)\n",
    "    # filter using ratio\n",
    "    good = []\n",
    "    for pair in matches:\n",
    "        try:\n",
    "            m,n = pair\n",
    "            if m.distance < ratio*n.distance:\n",
    "                good.append(m)\n",
    "        except ValueError:\n",
    "            print('Missing Match pair!')\n",
    "            pass\n",
    "    return good, matches\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preprocess kp/des for query image(s)\n",
    "\n",
    "img1 = cv2.imread('logos/rolex.jpg',0)          # queryImage\n",
    "# find the keypoints and descriptors\n",
    "kp1, des1 = siftKpAndDes(img1)\n",
    "\n",
    "img1kps = cv2.drawKeypoints(img1, kp1, None, color=(0,255,0), flags=0)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(img1kps), plt.show()\n",
    "\n",
    "print(len(kp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encoding params for quality when saving sample jpeg screenshots\n",
    "encoding_params = [int(cv2.IMWRITE_JPEG_QUALITY), 10]\n",
    "\n",
    "def runMatching(query, video, output_dir=\"outputs\", chain = 3, feature_ext = 'ORB', matcher = 'FLANN',\n",
    "               frame_interval = 1, ratio = 0.7, min_matches = 15):\n",
    "    print(feature_ext)\n",
    "    print(matcher)\n",
    "    positives = [] # list of frame numbers of positive indentifications\n",
    "    n_pos = 0\n",
    "    errors = [] # list of error frames to analyze later (hopefully should be empty!)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video)\n",
    "    img_chain = [] # list of past images in the current running chain of positive frames, up to the chain parameter\n",
    "    \n",
    "    # preprocess kp/des for query image(s)\n",
    "\n",
    "    img1 = cv2.imread(query,0) # queryImage\n",
    "    # find the keypoints and descriptors\n",
    "    kp1, des1 = orbKpAndDes(img1)\n",
    "    \n",
    "    while(True):\n",
    "        for i in range(frame_interval):\n",
    "            #skip i number of frames\n",
    "            cap.grab()\n",
    "\n",
    "        # Capture frame-by-frame and covert to grayscale\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Analysis finished!\")\n",
    "            #TODO: post-processing of CSV and image files\n",
    "            with open(os.path.join(output_dir,'results.csv'), 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['SUMMARY OF RESULTS'])\n",
    "                writer.writerow(['Query Image', 'Video', 'Chain Length', 'Feature Extractor', 'Matcher', \n",
    "                                 'Frame Interval', 'Pass Ratio', 'Match Thresh'])\n",
    "                write.writerow([query, video, chain, feature_ext, matcher, frame_interval, ratio, min_matches])\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #     # TESTING: MOG2 background subtractor mask\n",
    "    #     mask = subtractor.apply(gray, masked, 0.999)\n",
    "    #     masked = cv2.bitwise_and(gray, masked)\n",
    "    #     kp2, des2 = siftKpAndDes(masked)\n",
    "\n",
    "\n",
    "    #     # TESTING: Equalize historgram to incrase contrast (probably for ORB)\n",
    "    #     eh = cv2.equalizeHist(gray)\n",
    "    #     kp2, des2 = siftKpAndDes(eh)\n",
    "\n",
    "    #     # TESTING: Blurring with various LPFs\n",
    "    #     blurred = cv2.bilateralFilter(gray,9,75,75)\n",
    "    #     kp2, des2 = siftKpAndDes(blurred)\n",
    "\n",
    "        # DEFAULT: find the keypoints and descriptors\n",
    "        kp2, des2 = orbKpAndDes(gray)\n",
    "\n",
    "    #     # DEBUGGING: show only target image kps\n",
    "    #     img3 = cv2.drawKeypoints(blurred, kp2, None, color=(0,255,0), flags=0)\n",
    "    #     cv2.imshow('frame',img3)\n",
    "    #     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #         break\n",
    "    #     continue\n",
    "        try:\n",
    "            if matcher is 'FLANN':     \n",
    "                good, matches = flannMatcher(des1, des2, feature_type=feature_ext, ratio=ratio)\n",
    "            else: # else we use BF\n",
    "                good, matches = bfMatcher(des1, des2, feature_type=feature_ext, ratio=ratio)\n",
    "\n",
    "            if len(good) > min_matches:\n",
    "                print(len(good))\n",
    "                src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "                dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "                M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "\n",
    "                if M is None:\n",
    "                    # if homography matrix is empty\n",
    "                    print(\"Empty homography matrix\")\n",
    "                    img3 = gray # display image without any lines\n",
    "                else:\n",
    "        #             print(M)\n",
    "                    matchesMask = mask.ravel().tolist()\n",
    "                    h,w = img1.shape\n",
    "                    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "                    dst = cv2.perspectiveTransform(pts,M)\n",
    "\n",
    "                    # covert to color so homography line can be shown\n",
    "                    color = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "                    img3 = cv2.polylines(color,[np.int32(dst)],True,(0,255,0),3, cv2.LINE_AA)  \n",
    "            else:\n",
    "                print( \"Not enough matches are found - {}/{}\".format(len(good), min_matches) )\n",
    "                matchesMask = None\n",
    "                img3 = gray # display image without any lines\n",
    "\n",
    "        #     draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "        #                        singlePointColor = None,\n",
    "        #                        matchesMask = matchesMask, # draw only inliers\n",
    "        #                        flags = 2)\n",
    "        #     img3 = cv2.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    "\n",
    "        #     # Display the resulting frame\n",
    "        #     cv2.imshow('frame',gray)\n",
    "            print(chain)\n",
    "            print(len(img_chain))\n",
    "            \n",
    "        except cv2.error as e:\n",
    "            print('Matching Error! Recording and skipping this frame...')\n",
    "            errors.append(e)\n",
    "            pass\n",
    "\n",
    "        if len(good) > min_matches and M is not None:\n",
    "            img_chain.append(img3) # add this image to the current continuous chain of positive frames\n",
    "            if len(img_chain) is chain:\n",
    "                for img_in_chain in img_chain:\n",
    "                    n_pos += 1\n",
    "                    img_name = 'frame%d.jpg' % n_pos\n",
    "                    cv2.imwrite(os.path.join(output_dir, img_name), img3, encoding_params) # write with compression param as specified up top\n",
    "                    print(img_name)\n",
    "            elif len(img_chain) > chain:\n",
    "                n_pos += 1\n",
    "                img_name = 'frame%d.jpg' % n_pos\n",
    "                cv2.imwrite(os.path.join(output_dir, img_name), img3, encoding_params) # write with compression param as specified up top\n",
    "                print(img_name)\n",
    "        else:\n",
    "            img_chain = [] # if negative, then clear chain\n",
    "            \n",
    "        cv2.putText(img3, \"T.Count:\" + str(n_pos), (2,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "        cv2.putText(img3, \"Pos.Chain:\" + str(len(img_chain)), (2,60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "\n",
    "        cv2.imshow('frame',img3)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    return positives, n_pos, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runner\n",
    "# TODO: make all params specified here!\n",
    "\n",
    "FRAME_INTERVAL = 1\n",
    "MIN_MATCH_COUNT =  15 #RULE: >10% of keypoints in query image? -> work well only fort scale-invarient (SIFT)\n",
    "RATIO = 0.7 #lowered from 0.7 to derease sensitivity\n",
    "\n",
    "runMatching('logos/rolex.jpg', 'videos/15brazil-5min.mp4', output_dir='outputs', chain=3,\n",
    "            feature_ext = 'ORB', matcher='FLANN',\n",
    "            frame_interval=FRAME_INTERVAL, ratio=RATIO, min_matches=MIN_MATCH_COUNT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
