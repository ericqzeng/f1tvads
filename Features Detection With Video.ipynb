{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from sortedcontainers import SortedKeyList, SortedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOB subtractor\n",
    "subtractor = cv2.createBackgroundSubtractorMOG2(detectShadows=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kp and des methods\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "def siftKpAndDes(frame):\n",
    "    return sift.detectAndCompute(frame,None)\n",
    "\n",
    "surf = cv2.xfeatures2d.SURF_create()\n",
    "def surfKpAndDes(frame):\n",
    "    return surf.detectAndCompute(frame,None)\n",
    "\n",
    "star = cv2.xfeatures2d.StarDetector_create()\n",
    "def fastKp(frame):\n",
    "    return star.detect(frame,None)\n",
    "\n",
    "brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "def briefDes(frame, kps):\n",
    "    return brief.compute(frame, kps)\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "def orbKpAndDes(frame):\n",
    "    return orb.detectAndCompute(frame,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matcher methods\n",
    "\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "FLANN_KDTREES = 5\n",
    "\n",
    "FLANN_INDEX_LSH = 6\n",
    "TABLE_NUMBER = 6 #12\n",
    "KEY_SIZE = 12 #20\n",
    "MULTI_PROBE_LEVEL = 1 #2\n",
    "SEARCH_CHECKS = 50\n",
    "\n",
    "#BF matching\n",
    "bf_orb = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "bf_sift = cv2.BFMatcher()\n",
    "def bfMatcher(des1, des2, feature_type = 'SIFT', ratio = 0.7):\n",
    "\n",
    "    if feature_type is 'ORB': \n",
    "        matches = bf_orb.knnMatch(des1,des2,k=2)\n",
    "    else:\n",
    "        matches = bf_sift.knnMatch(des1, des2, k=2)\n",
    "    # filter using ratio\n",
    "    good = []\n",
    "    for pair in matches:\n",
    "        try:\n",
    "            m,n = pair\n",
    "            if m.distance < ratio*n.distance:\n",
    "                good.append(m)\n",
    "        except ValueError:\n",
    "            print('Missing Match pair!')\n",
    "            passq\n",
    "    return good, matches\n",
    "\n",
    "\n",
    "#FLANN-based\n",
    "search_params = dict(checks = SEARCH_CHECKS)\n",
    "flann_orb = cv2.FlannBasedMatcher(dict(algorithm = FLANN_INDEX_LSH,\n",
    "                   table_number = TABLE_NUMBER,\n",
    "                   key_size = KEY_SIZE,\n",
    "                   multi_probe_level = MULTI_PROBE_LEVEL),\n",
    "                   search_params)\n",
    "flann_sift = cv2.FlannBasedMatcher(dict(algorithm = FLANN_INDEX_KDTREE, trees = FLANN_KDTREES), \n",
    "                                   search_params )\n",
    "def flannMatcher(des1, des2, feature_type = 'SIFT', ratio=0.7):\n",
    "    \n",
    "    if feature_type is 'ORB': \n",
    "        matches = flann_orb.knnMatch(des1, des2, k=2)\n",
    "    else:\n",
    "        matches = flann_sift.knnMatch(des1, des2, k=2)\n",
    "    # filter using ratio\n",
    "    good = []\n",
    "    for pair in matches:\n",
    "        try:\n",
    "            m,n = pair\n",
    "            if m.distance < ratio*n.distance:\n",
    "                good.append(m)\n",
    "        except ValueError:\n",
    "            print('Missing Match pair!')\n",
    "            pass\n",
    "    return good, matches\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preprocess kp/des for query image(s)\n",
    "\n",
    "img1 = cv2.imread('logos/genii.jpg',0)          # queryImage\n",
    "# find the keypoints and descriptors\n",
    "kp1, des1 = siftKpAndDes(img1)\n",
    "\n",
    "img1kps = cv2.drawKeypoints(img1, kp1, None, color=(0,255,0), flags=0)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(img1kps), plt.show()\n",
    "\n",
    "print(len(kp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encoding params for quality when saving sample jpeg screenshots\n",
    "encoding_params = [int(cv2.IMWRITE_JPEG_QUALITY), 10]\n",
    "\n",
    "def runMatching(query, video, output_dir=\"outputs\", chain = 3, feature_ext = 'ORB', matcher = 'FLANN',\n",
    "               frame_interval = 1, ratio = 0.7, min_matches = 15, fps=30):\n",
    "    print(chain)\n",
    "    print(feature_ext)\n",
    "    print(matcher)\n",
    "    print(frame_interval)\n",
    "    print(ratio)\n",
    "    print(min_matches)\n",
    "    \n",
    "    positives = dict() # dict of frame numbers of positive indentifications\n",
    "    n_pos = 0 # total count of positives\n",
    "    errors = [] # list of error frames to analyze later (hopefully should be empty!)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video)\n",
    "    img_chain = [] # list of past images in the current running chain of positive frames, up to the chain parameter\n",
    "    \n",
    "    # preprocess kp/des for query image(s)\n",
    "    img1 = cv2.imread(query, 0)\n",
    "    if feature_ext is 'ORB':     \n",
    "        kp1, des1 = orbKpAndDes(img1)\n",
    "    elif feature_ext is 'SIFT':\n",
    "        kp1, des1 = siftKpAndDes(img1)\n",
    "    else:\n",
    "        # no features or matching\n",
    "        kp1, des1 = [], []\n",
    "    \n",
    "    \n",
    "    # frame number tracker\n",
    "    frame_n = 0\n",
    "    \n",
    "    # start time for running speed measure\n",
    "    start_t = time.process_time()\n",
    "    delta = ''\n",
    "    \n",
    "    while(True):\n",
    "        for i in range(frame_interval - 1):\n",
    "            #skip i number of frames\n",
    "            cap.grab()\n",
    "\n",
    "        # Capture frame-by-frame and covert to grayscale\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Analysis finished!\")\n",
    "            # TODO: post-processing of CSV and image files\n",
    "            with open(os.path.join(output_dir,'results.csv'), 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['SUMMARY OF PARAMS'])\n",
    "                writer.writerow(['Query Image', 'Video', 'Chain Length', 'Feature Extractor', 'Matcher', \n",
    "                                 'Frame Interval', 'Pass Ratio', 'Match Thresh'])\n",
    "                writer.writerow([query, video, chain, feature_ext, matcher, frame_interval, ratio, min_matches])\n",
    "                writer.writerow(['MATCHES'])\n",
    "                writer.writerow(['Frame Num', 'Img Name'])\n",
    "                for match in positives.items():\n",
    "                    writer.writerow([match[0], match[1]])\n",
    "                    # TODO: more metadata later\n",
    "            break\n",
    "            \n",
    "        frame_n += 1 # ret is True, frame found, continue processing\n",
    "        \n",
    "        # running speed display (delta is % speed of realtime according to input fps and frame interval)\n",
    "        if frame_n % fps is 0:\n",
    "            end_t = time.process_time()\n",
    "            delta = int((100.0 * frame_interval) / (end_t - start_t))\n",
    "            delta = \" (\" + str(delta) + \"%)\"\n",
    "            start_t = time.process_time()\n",
    "            \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#         # TESTING: MOG2 background subtractor mask\n",
    "#         mask = subtractor.apply(gray, masked, 0.999)\n",
    "#         masked = cv2.bitwise_and(gray, masked)\n",
    "#         kp2, des2 = siftKpAndDes(masked)\n",
    "\n",
    "#         # TESTING: Equalize historgram to incrase contrast (probably for ORB)\n",
    "#         eh = cv2.equalizeHist(gray)\n",
    "#         kp2, des2 = siftKpAndDes(eh)\n",
    "\n",
    "#         # TESTING: Blurring with various LPFs\n",
    "#         blurred = cv2.bilateralFilter(gray,9,75,75)\n",
    "#         kp2, des2 = siftKpAndDes(blurred)\n",
    "\n",
    "        # DEFAULT: find the keypoints and descriptors\n",
    "        if feature_ext is 'ORB':     \n",
    "            kp2, des2 = orbKpAndDes(gray)\n",
    "        elif feature_ext is 'SIFT':\n",
    "            kp2, des2 = siftKpAndDes(gray)\n",
    "        else:\n",
    "            # no features or matching\n",
    "            cv2.putText(gray, \"Frame.Num: \" + str(frame_n) + delta, (2, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "            cv2.imshow('frame', gray)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            continue\n",
    "\n",
    "\n",
    "        # list of good matches (need to init to empty for debug mode)\n",
    "        good = []\n",
    "        try:\n",
    "            if matcher is 'FLANN':\n",
    "                good, matches = flannMatcher(des1, des2, feature_type=feature_ext, ratio=ratio)\n",
    "            elif matcher is 'BF':\n",
    "                good, matches = bfMatcher(des1, des2, feature_type=feature_ext, ratio=ratio)\n",
    "            else:\n",
    "                # DEBUGGING: show only target image kps, no matching run\n",
    "                img3 = cv2.drawKeypoints(gray, kp2, None, color=(0,255,0), flags=0)\n",
    "                cv2.putText(img3, \"Frame.Num: \" + str(frame_n) + delta, (2, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "                cv2.imshow('frame',img3)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                continue\n",
    "                \n",
    "\n",
    "            if len(good) > min_matches:\n",
    "                print(len(good))\n",
    "                src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "                dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "                M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "\n",
    "                if M is None:\n",
    "                    # if homography matrix is empty\n",
    "                    print(\"Empty homography matrix\")\n",
    "                    img3 = gray # display image without any lines\n",
    "                else:\n",
    "#                     print(M)\n",
    "                    matchesMask = mask.ravel().tolist()\n",
    "                    h,w = img1.shape\n",
    "#                     pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "                    pts = np.float32([ [0,0],[w-1,0],[w-1,h-1],[0,h-1] ]).reshape(-1,1,2) # cw direction\n",
    "                    dst = cv2.perspectiveTransform(pts,M)\n",
    "                \n",
    "                    # TODO: analyze shpae of dst, checking it is reasonable\n",
    "                    print(dst)\n",
    "\n",
    "                    # covert to color so homography line can be shown\n",
    "                    color = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "                    img3 = cv2.polylines(color,[np.int32(dst)],True,(0,255,0),3, cv2.LINE_AA)  \n",
    "            else:\n",
    "                print( \"Not enough matches are found - {}/{}\".format(len(good), min_matches) )\n",
    "                matchesMask = None\n",
    "                img3 = gray # display image without any lines\n",
    "\n",
    "#             draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "#                                singlePointColor = None,\n",
    "#                                matchesMask = matchesMask, # draw only inliers\n",
    "#                                flags = 2)\n",
    "#             img3 = cv2.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    "\n",
    "#             # Display the resulting frame\n",
    "#             cv2.imshow('frame',gray)\n",
    "            \n",
    "        except cv2.error as e:\n",
    "            print('Matching Error! Recording and skipping this frame...')\n",
    "            img3 = gray # display image without any lines\n",
    "            print(e)\n",
    "            errors.append(e)\n",
    "\n",
    "        #  saving samples positives images\n",
    "        # TODO: save only the single median image in each group of 5?\n",
    "        if len(good) > min_matches and M is not None:\n",
    "            img_chain.append(img3) # add this image to the current continuous chain of positive frames\n",
    "            if len(img_chain) is chain:\n",
    "                for i,img_in_chain in enumerate(img_chain):\n",
    "                    n_pos += 1\n",
    "                    img_name = 'frame%d.jpg' % (frame_n - chain + 1 + i)\n",
    "                    cv2.imwrite(os.path.join(output_dir, img_name), img_in_chain, encoding_params) # write with compression param as specified up top\n",
    "                    positives[frame_n - chain + 1 + i] = img_name\n",
    "                    print(img_name)\n",
    "            elif len(img_chain) > chain:\n",
    "                n_pos += 1\n",
    "                img_name = 'frame%d.jpg' % frame_n\n",
    "                cv2.imwrite(os.path.join(output_dir, img_name), img3, encoding_params) # write with compression param as specified up top\n",
    "                positives[frame_n] = img_name\n",
    "                print(img_name)\n",
    "                \n",
    "#             if len(img_chain) % chain is 0:\n",
    "        \n",
    "        else:\n",
    "            img_chain = [] # if negative, then clear chain\n",
    "            \n",
    "        cv2.putText(img3, \"T.Count: \" + str(n_pos), (2,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "        cv2.putText(img3, \"Pos.Chain: \" + str(len(img_chain)), (2,60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "        cv2.putText(img3, \"Frame.Num: \" + str(frame_n) + delta, (2, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "\n",
    "        cv2.imshow('frame',img3)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    return positives, n_pos, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runner\n",
    "# TODO: make all params specified here!\n",
    "# TODO: make a metadata object to store information on each image frame for csv output\n",
    "\n",
    "FRAME_INTERVAL = 2 # 1 means no frame skips\n",
    "MIN_MATCH_COUNT =  15 #RULE: >10% of keypoints in query image? -> work well only fort scale-invarient (SIFT)\n",
    "RATIO = 0.7 #lowered from 0.7 to derease sensitivity\n",
    "\n",
    "runMatching('logos/rolex.jpg', 'videos/15brazil-5min.mp4', output_dir='outputs', chain=3,\n",
    "            feature_ext = 'ORB', matcher='FLANN',\n",
    "            frame_interval=FRAME_INTERVAL, ratio=RATIO, min_matches=MIN_MATCH_COUNT, fps=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersection of two segments given their endpoints\n",
    "# This code is contributed by Ansh Riyal \n",
    "\n",
    "class Point: \n",
    "    def __init__(self, x, y): \n",
    "        self.x = x \n",
    "        self.y = y\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return self.x is other.x and self.y is other.y\n",
    "        \n",
    "    def __lt__(self, other):\n",
    "        return self.x < other.x or (self.x is other.x and self.y < other.y)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Point(\" + str(self.x) + \", \" + str(self.y) + \")\"\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(str(self.x) + ',' + str(self.y))\n",
    "        \n",
    "  \n",
    "# Given three colinear points p, q, r, the function checks if  \n",
    "# point q lies on line segment 'pr'  \n",
    "def onSegment(p, q, r): \n",
    "    if ( (q.x <= max(p.x, r.x)) and (q.x >= min(p.x, r.x)) and \n",
    "           (q.y <= max(p.y, r.y)) and (q.y >= min(p.y, r.y))): \n",
    "        return True\n",
    "    return False\n",
    "  \n",
    "def orientation(p, q, r): \n",
    "    # to find the orientation of an ordered triplet (p,q,r) \n",
    "    # function returns the following values: \n",
    "    # 0 : Colinear points \n",
    "    # 1 : Clockwise points \n",
    "    # 2 : Counterclockwise \n",
    "      \n",
    "    # See https://www.geeksforgeeks.org/orientation-3-ordered-points/amp/  \n",
    "    # for details of below formula.  \n",
    "      \n",
    "    val = (float(q.y - p.y) * (r.x - q.x)) - (float(q.x - p.x) * (r.y - q.y)) \n",
    "    if (val > 0): \n",
    "          \n",
    "        # Clockwise orientation \n",
    "        return 1\n",
    "    elif (val < 0): \n",
    "          \n",
    "        # Counterclockwise orientation \n",
    "        return 2\n",
    "    else: \n",
    "          \n",
    "        # Colinear orientation \n",
    "        return 0\n",
    "  \n",
    "# the main function that returns true if  \n",
    "# the line segment 'p1q1' and 'p2q2' intersect. \n",
    "def doIntersect(p1,q1,p2,q2): \n",
    "      \n",
    "    # Find the 4 orientations required for  \n",
    "    # the general and special cases \n",
    "    o1 = orientation(p1, q1, p2) \n",
    "    o2 = orientation(p1, q1, q2) \n",
    "    o3 = orientation(p2, q2, p1) \n",
    "    o4 = orientation(p2, q2, q1) \n",
    "  \n",
    "    # General case \n",
    "    if ((o1 != o2) and (o3 != o4)): \n",
    "        return True\n",
    "  \n",
    "    # Special Cases \n",
    "  \n",
    "    # p1 , q1 and p2 are colinear and p2 lies on segment p1q1 \n",
    "    if ((o1 == 0) and onSegment(p1, p2, q1)): \n",
    "        return True\n",
    "  \n",
    "    # p1 , q1 and q2 are colinear and q2 lies on segment p1q1 \n",
    "    if ((o2 == 0) and onSegment(p1, q2, q1)): \n",
    "        return True\n",
    "  \n",
    "    # p2 , q2 and p1 are colinear and p1 lies on segment p2q2 \n",
    "    if ((o3 == 0) and onSegment(p2, p1, q2)): \n",
    "        return True\n",
    "  \n",
    "    # p2 , q2 and q1 are colinear and q1 lies on segment p2q2 \n",
    "    if ((o4 == 0) and onSegment(p2, q1, q2)): \n",
    "        return True\n",
    "  \n",
    "    # If none of the cases \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line class by Eric Zeng\n",
    "class Line:\n",
    "    def __init__(self, p, q):\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "        self.key = \"Line[\" + str(self.p) + \"-\" + str(self.q) + \"]\"\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return (self.p is other.p and self.q is other.q)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.p < other.p\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Line[\" + str(self.p) + \"-\" + str(self.q) + \"]\"\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(str(self.p) + '-' + str(self.q))\n",
    "    \n",
    "    \n",
    "def endsCoincident(p1, p2):\n",
    "    return p1.p == p2.p or p1.p == p2.q or p1.q == p2.p or p1.q == p2.q\n",
    "\n",
    "# assumes pts are 4 points creating a closed quad\n",
    "# electing to use list instead of BST or other varients since n=4 (finite, known, and very small)\n",
    "# This implementation was written by Eric Zeng\n",
    "def checkSimplePolygon(pts):\n",
    "    # create 4 segments\n",
    "    # sort the endpoints in each segment to have the smaller x value be first\n",
    "    segs = [\n",
    "            sorted([Point(pts[0][0][0], pts[0][0][1]), Point(pts[1][0][0], pts[1][0][1])]), \n",
    "            sorted([Point(pts[1][0][0], pts[1][0][1]), Point(pts[2][0][0], pts[2][0][1])]),\n",
    "            sorted([Point(pts[2][0][0], pts[2][0][1]), Point(pts[3][0][0], pts[3][0][1])]),\n",
    "            sorted([Point(pts[3][0][0], pts[3][0][1]), Point(pts[0][0][0], pts[0][0][1])])\n",
    "           ]\n",
    "    # sort all segments against each other using the starting endpoint's x value\n",
    "    segs = sorted(segs, key = lambda x: x[0])\n",
    "    segs = [Line(s[0], s[1]) for s in segs] # covert sublists to lines\n",
    "    \n",
    "    # init event queue, marking {\"Adds\" and \"Exit\" endpoints -> Line} mappings\n",
    "    eventq = SortedDict()\n",
    "    for s in segs:\n",
    "        left = str(s.p) + \"A\"\n",
    "        right = str(s.q) + \"E\"\n",
    "        if (left not in eventq):\n",
    "            eventq.update({left: list()})\n",
    "        if (right not in eventq):\n",
    "            eventq.update({right: list()})\n",
    "            \n",
    "        eventq.get(left).append(s)\n",
    "        eventq.get(right).append(s)\n",
    "    \n",
    "#     [print(a) for a in eventq]\n",
    "\n",
    "    # init sweep line\n",
    "    sl = SortedKeyList([], lambda x: x.key)\n",
    "    for e in eventq:\n",
    "#         print(e)\n",
    "#         print('targets: ' + \",\".join(str(line) for line in eventq[e]))\n",
    "        if e[-1] is 'A':\n",
    "#             print('ADDS')\n",
    "            for i, line in enumerate(eventq[e]):\n",
    "                sl.add(line)\n",
    "#                 print(line)\n",
    "                try: \n",
    "#                     print('above')\n",
    "                    above = sl[sl.index(line) + 1]\n",
    "                    if (not endsCoincident(above, line)) and doIntersect(above.p, above.q, line.p, line.q):\n",
    "                        return False\n",
    "                except IndexError:\n",
    "                    pass # missing above\n",
    "                try: \n",
    "#                     print('below')\n",
    "                    below = sl[sl.index(line) - 1]\n",
    "                    if (not endsCoincident(below, line)) and doIntersect(below.p, below.q, line.p, line.q):\n",
    "                        return False\n",
    "                except IndexError:\n",
    "                    pass # missing above\n",
    "        else:\n",
    "#             print('REMOVES')\n",
    "            for i, line in enumerate(eventq[e]):\n",
    "                # check above and below intersections if not conincident\n",
    "                try:\n",
    "#                     print('both')\n",
    "                    above = sl[sl.index(line) + 1]\n",
    "                    below = sl[sl.index(line) - 1]\n",
    "                    if (not endsCoincident(above, below)) and doIntersect(above.p, above.q, below.p, below.q):\n",
    "                        return False\n",
    "                except IndexError:\n",
    "                    pass # missing either/both line above or below in SL, no need for additional check\n",
    "                 \n",
    "                # once check is done, discard this line from the SL\n",
    "                \n",
    "                sl.remove(line)\n",
    "\n",
    "#         [print(l) for l in sl]\n",
    "#         print()\n",
    "    \n",
    "    return True\n",
    "\n",
    "# testpoly = [[[30, 30]], [[56, 56]], [[52, 32]], [[32, 52]] ]\n",
    "\n",
    "# test = cv2.polylines(img1,[np.int32(testpoly)],True,(0,255,0),3, cv2.LINE_AA)  \n",
    "\n",
    "# plt.figure(figsize=(20,20))\n",
    "# plt.imshow(test)\n",
    "\n",
    "# checkSimplePolygon(testpoly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 program to evaluate \n",
    "# area of a polygon using \n",
    "# shoelace formula, clockwise in opencv coordinate system\n",
    "# \n",
    "# NOTE: assumes polygon is simple and closed (non-intersecting)\n",
    "# please check before simple property before running\n",
    "\n",
    "\n",
    "# (X[i], Y[i]) are coordinates of i'th point. \n",
    "\n",
    "# This code is contributed by \n",
    "# Smitha Dinesh Semwal \n",
    "# https://www.geeksforgeeks.org/area-of-a-polygon-with-given-n-ordered-vertices/\n",
    "def polygonArea(points): \n",
    "    \n",
    "    #transform list of Point object to two lists of X and Y coordinates\n",
    "    X = []\n",
    "    Y = []\n",
    "    for p in points:\n",
    "        X.append(p.x)\n",
    "        Y.append(p.y)\n",
    "        \n",
    "    print(X)\n",
    "    print(Y)\n",
    "    print(len(points))\n",
    "  \n",
    "    # Initialze area \n",
    "    area = 0.0\n",
    "  \n",
    "    # Calculate value of shoelace formula \n",
    "    j = len(points) - 1\n",
    "    for i in range(0,n): \n",
    "        area += (X[j] + X[i]) * (Y[j] - Y[i]) \n",
    "        j = i   # j is previous vertex to i \n",
    "      \n",
    "  \n",
    "    # Return absolute value \n",
    "    return abs(area / 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "doIntersect(Point(30,30), Point(56,56), Point(32,52), Point(52,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
